---
title: "Writing graveyard"
author: "Nicholas Spyrison"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 2019_01_21 from 03-spinifex

<!-- ### rambling about tours in the introduction -->

<!-- Both classical and contemporary visualizations of data are presented in $d=2$ dimensions, that of a computer monitor or in print. How is it that we come to view and share data that exists in $p > 3$ dimensions? In an appeal to brevity we shall ignore model and parameter summarization due to there shortcomings [@anscombe_graphs_1973; @matejka_same_2017]. Within the realm of data-space visualization we are left with projecting higher volumes and embedding them within lower dimensional spaces that we can visualize. -->

<!-- This is not a new phenomena, such linear projections have been in use for quite some time. [@pearson_liii._1901; @fisher_use_1936] and the myriad of single value decomposition (SVD) techniques from numerous disciplines use such embeddings. Previous application look at data in one (or few) static orientations, after some objective optimization. For instance in PCA, we reorient $p$-dimensions such that we have a reference to the ordered components that describe a descending amount of variation held within the data. Yet we still have $p$ components remaining to visualize. Where does the dimension reduction come in? From plotting only the first two or three and potentially another dimension tied to data point aesthetic. This is maximizes the amount of variation that can be display in an embedding, but regularly discards a large proportion of the variation held within the data. -->

<!-- More recently non-linear dimensionality techniques have become popular, such as t-distributed stochastic neighbor embedding (t-SNE) [@maaten_visualizing_2008], building off of Sammon mappings [@sammon_nonlinear_1969]. Such non-linear methods make for astounding distinction when in lower embeddings, but contain inherent shortcomings. Namely: that the non-linear transformations lack transparency back to the original data-space, and that they can suffer from overfitting. If there is no inherent clustering with the data, it's possible that noise within the variables may become the prominent feature and be displayed erroneously as group clustering. -->

<!-- TODO: Clean up touring, , below -->

<!-- [@asimov_grand_1985; @buja_grand_1986] first suggested grand tours in which random walks in $p$-space can be interpolated and embedded in $d$ dimensions which are then viewed in sequence. Imagine. Consider,  -->


<!-- The broader scope of touring has some beneficial features, namely: touring keeps the original dimensionality in tact unlike tradition static linear-projections, and maintains transparency back to the original dimensions, a primary drawback of non-linear dimensionality reduction. -->

<!-- TODO: clean up above, talk about touring in general first -->

<!-- ### Terminology and demystifying projection: -->
<!-- TODO: clean up the terminology section -->
<!-- basis, data, n, p, d, -->

<!-- Suppose that we have tri-variate data, $\textbf{X}_{[8,~3]}$, the corners points of a rectanguloid. We can describe the relative orientation by defining -->

<!-- For every $p$-dimensional space can be described by the direction and magnitude of axes in a square matrix that we call a basis. Imgine 3 axes of an XYZ Caresian volume (*ie.* a basis $\in \mathbb{R}^p$). In matimatical form we would write this as a diagonal identity matrix of demension 3. -->

<!-- ```{r} -->
<!-- # b <- diag(3) -->
<!-- # xyz <- c("X", "Y", "Z") -->
<!-- # rownames(b) <- xyz -->
<!-- # colnames(b) <- xyz -->
<!-- # b -->
<!-- ``` -->

<!-- This basis has some nice properties that are mathimatically nice to preserve, namely, that each axis as is at a right angle to the other (*orthagonal*), and are unit *normal* (length or norm equal to one). If matrix meets both of these criteria we call it *orthonormal*. -->

<!-- ```{r} -->
<!-- # set.seed(15) -->
<!-- # library(plotly) -->
<!-- # library(processx) -->
<!-- # X = 9*runif(100) # X = 9*c(0,1,1,0,0,1,1,0) -->
<!-- # Y = 6*runif(100) # Y = 6*c(0,0,1,1,0,0,1,1) -->
<!-- # Z = 2*runif(100) # Z = 2*c(0,0,0,0,1,1,1,1) -->
<!-- # -->
<!-- # p <- plot_ly(x=X, y=Y, z=Z, type="scatter3d", mode="markers") -->
<!-- # ###STATIC OUTPUT REQURIES ORCA SETUP, NOT TRANsFERABLE... -->
<!-- # # orca(p, "cube_demo.png") # but, needs orca setup, -->
<!-- # # plotly_IMAGE(p, format = "png", out_file = "output.png") -->
<!-- ``` -->

<!-- ### Illustrating flea and breast cancer -->

<!-- Let: -->
<!-- \begin{description} -->
<!--   \item[$d=2$] For illustration's sake, we'll embed into 2 dimensions. -->
<!-- \end{description} -->

<!-- Given: -->
<!-- \begin{description} -->
<!--   \item[$\bf{X}_{[74,~6]}$] Flea data, 74 observations by 6 variables, $\bf{X} \in \mathbb{R}^6, ~p=6$. -->
<!--   \item[$p=6$] -->
<!-- \end{description} -->

<!-- Let's initialize a random orthonormal basis of dimensions [$p,~d$], which describes a random orientation projected from 6 down to 2 dimensions. Check how each of the dimensions is contributing the XY components with `view_basis()` -->

<!-- TODO: reference fig 1, keep in mind that the figure floats more than the table. -->
<!-- TODO: consider adding a `view_manip_sp()` function with phi and theata, etc. -->

<!-- ```{r, fig.cap = "Random basis, flea data"} -->
<!-- library(spinifex) -->

<!-- flea_std <- rescale(flea[, 1:6]) -->
<!-- rb <- basis_random(ncol(flea_std), 2) -->
<!-- view_basis(basis = rb, labels = colnames(flea_std))  -->
<!-- ``` -->

<!-- Perform a manual tour on the random basis with `manual_tour()`, We'll arbitratrily choose the 4th variable, aede1, and let the default selection of `phi` go from it's start, to 0 radians, to pi/2 radians, and back to the start position. In turn the norm of manipualtion variable goes to 1 and then 0, before returning to it's inital position.  -->

<!-- ```{r, fig.cap = "Manual tour, flea data", echo = TRUE, eval=FALSE} -->
<!-- mtour <- manual_tour(basis = rb, manip_var = 4) -->
<!-- mslides <- create_slides(tour = mtour, data = flea_std) -->

<!-- render_plotly(mslides) -->
<!-- ``` -->
<!--  TODO: write follow up and segway into breast cancer; play_tour (holes), explore local area.  -->
<!--  TODO: note that render_plotly didn't add the figure caption. -->


## 2019_01_28 from chap3 spinifex atb at making function to clean code.

THIS IS SLIGHTLY OUT DATED GOING TO WEBSITE TO PULL.
```{r}
library(spinifex)
load("./data/jetsProj_sub.rda") # fig 7, subset of ATLAS7old and ATLAS7new
load("./data/PDFSense_fig7_basis.rda") # fi 7
load("./data/grDIScenter.rda") # fig 8, left
load("./data/grDISsphere.rda") # fig 8, right
load("./data/PDFSense_fig8l_basis.rda") # fig 8, left
# load("./data/PDFSense_fig8r_basis.rda") # fig 8, right

# Fig 7, subset of ATLAS7old and ATLAS7new
view_basis(fig7_basis)
play_manual_tour(data = jetsProj_sub[, 1:4], basis = fig7_basis, manip_var = 3,
                 cat_var = jetsProj_sub$exp)
play_manual_tour(data = jetsProj_sub[, 1:4], basis = fig7_basis, manip_var = 4,
                 cat_var = jetsProj_sub$exp)

# Fig 8,
view_basis(fig8l_basis)
play_manual_tour(data = grDIScenter[, 1:6], basis = fig8l_basis, manip_var = 6,
                 cat_var = grDIScenter$disID)
play_manual_tour(data = grDIScenter[, 1:6], basis = fig8l_basis, manip_var = 5,
                 cat_var = grDIScenter$disID)
```

## 2019_01_28 from chap 3 trouble shooting manual_tour

outdated:
```{r, eval=F,include=F}
#TODO: TORUBLESHOOT HERE;; EVAL=F,INCLUDE=F
b1 <- basis_slides[basis_slides$slide==1,1:2]
m1 <- mtour[,,1] #m tour, from h_bas,

view_basis(h_bas) #TARGET
view_basis(b1) # WRONG, BACK UP
view_basis(m1) # WRONG;
print("wrong before b1 at m1; meaning issue in manual_tour, which seemed to work for example...")

# REPRODUCE FROM EXAMPEL:
DAT <- tourr::rescale(tourr::flea[,1:6])
BAS <- tourr::basis_random(n = ncol(DAT))
MT  <- manual_tour(basis = BAS, manip_var = 5) # HOMOMORPHISM...
view_basis(BAS) #TARGET
view_basis(MT[,,1]) #WRONG; WORK BACK FROM MANUAL_tour
view_manip_space(BAS, 5) #GOOD
M_SP    <- create_manip_space(basis = BAS, manip_var = 5)
view_basis(M_SP[,1:2]) #GOOD
theta <- atan(BAS[m_var, 2] / BAS[m_var, 1])
P_ST      <- acos(sqrt(BAS[m_var, 1]^2 + BAS[m_var, 2]^2))
R_SP <- rotate_manip_space(manip_space = M_SP, theta = theta, phi = P_ST)[, 1:2]
view_basis(R_SP)
#INIT

phi_start_sign <- P_ST * sign(M_SP[m_var, 1]) 
phi_inc        <- pi / (n_sli - 3)
p              <- nrow(BAS)
d              <- ncol(BAS)
seq_start <- NULL; seq_end <- NULL
W1 <- interpolate_walk(P_ST,P_ST)
```

## 2019_01_29 from _firgures.r, initial code for spinifex, chap3


```{r}
rep(print("THIS WAS INITIAL DOCUMENT AND MAY BE STALE. CHAPTER CODE SHOULD BE TRUSTED OVER THIS."),3)

library(spinifex)
library(ggplot2)
library(gridExtra)
set.seed(1) #don't think this matters, but can't hurt.

# ## FLEA HOLES TOUR
# flea_std <- tourr::rescale(tourr::flea[,1:6])
# hpath    <- tourr::save_history(flea_std, tourr::guided_tour(tourr::holes))
# h_bas    <- matrix(hpath[,,max(dim(hpath)[3])], ncol=2)
#
# #0_left
# step0_l <- view_basis(h_bas) # Maybe manual tour on v1?
#
# h_m_sp <- create_manip_space(h_bas, manip_var = 1)
# h_dat  <- cbind(data.frame(flea_std %*% h_m_sp[, 1:2]), flea$species)
# colnames(h_dat) <- c("x", "y", "species")
#
# #0_right
# step0_r <- ggplot() +
#   geom_point(h_dat, mapping = aes(x=x, y=y, color=species)) +
#   scale_color_brewer(palette = "Dark2") +
#   theme_void() +
#   theme(legend.position=c(0.8, 0.8)) +
#   theme(legend.background = element_rect(colour = 'black', fill = 'grey90', linetype='solid'))
#
#
# #=== Step 0 out
# step0 <- grid.arrange(step0_l, step0_r, ncol=2)
# ggsave("./output/step0_basis+proj.png", step0,
#        height = 4, width = 4*1.61, units = "in")

#=== Step 2 out
step2 <- view_manip_sp(h_bas, 5)
ggsave("./output/step2_manip_sp.png", step2,
       width = 4, height = 4, units = "in")


#===
mtour <- manual_tour(h_bas, manip_var = 5, n_slides = 15)
bases <- create_slides(tour = mtour, data = flea_std)
bases <- bases$basis_slides

mag <- 2.2
grid  <- data.frame(slide = 1:15, x = mag*rep(1:5, 3), y = mag*rep(3:1, each = 5))

# Initialize
## manip var asethetics
n_slides         <- max(bases$slide)
p                <- nrow(bases) / n_slides
manip_var        <- 5
col_v            <- rep("grey80", p)
col_v[manip_var] <- "blue"
col_v            <- rep(col_v, n_slides)
siz_v            <- rep(0.3, p)
siz_v[manip_var] <- 1
siz_v            <- rep(siz_v, n_slides)
## circle
angle <- seq(0, 2 * pi, length = 180)
circ  <- data.frame(c_x = cos(angle), c_y = sin(angle))
circ[nrow(circ)+1, ] <- NA

bases_grid <- merge(x = bases, y = grid, by = "slide", all = TRUE) # OUTER JOIN
circ_grid <- merge(x = circ, y = grid, by = NULL) # CROSS JOIN,

#=== Step 3 out
(step3 <- ggplot(data = bases_grid) +
  geom_segment(aes(x = V1+x, y = V2+y, xend = x, yend = y),
               color = col_v, size = siz_v) +
  geom_text(aes(x = V1+x, y = V2+y, label = lab_abbr),
            color = col_v, vjust = "outward", hjust = "outward") +
  geom_path(data = circ_grid, mapping = aes(x = x+c_x, y = y+c_y), color = "grey80") +
  theme_void())
ggsave("./output/step3_manual_tour.png", step3, width = 4*(5/3), height = 4)


```

## 2019_02_08 from intro


<!--In the chapters below we will be discussing touring, a sequence of orthogonal linear projections viewed as an animation while the basis varies, changing the orientation and hence the projection. Traditionally techniques such as principal component analysis and linear discriminant analysis (PCA and LDA respectively) use the same orthogonal projection, but only for a single frame and variation out side of 2 or 3 linear components because a casually. More recently non-linear techniques such as multi-dimensional scaling (MDS), and t-distributed stochastic nearest neighbor embedding (t-SNE) are astounding for classification but lose transparency back to the original variables and can suffer from overfitting. Touring maintains variable transparency, and preserves information held with the projections by viewing many orientations over time, making touring a front-running technique for the exploratory data analysis of numeric multivariate data spaces.

The chapter \ref{ch:lit_review}, is a literature review focusing on the tour methodology and taxonomy before breaking into sections focusing each reasearch quiestion respenctively. For the touring section I expound upon touring and discuss the history, before discussing tour path generation, and display geometrics that are intrinsically linked to the dimension of the embedding. A list of past touring software implementations is also listed.
-->

<!--
The primary question I am expoloring is:
TODO:

Aim 1 of my thesis is to extend upon the R touring package, *tourr*, by adding manual tours, extending to recent graphic and animation packages, implement to look at function sections. Chapter \ref{ch:spinifex}, *spinifex*, discusses the implementing manual tours in R and the associated R package, *spinifex*, and also extends display the packages *plotly* and *gganimate*. We are in the process of editing the associated paper which will be submitted to the R Journal for publication shortly. Function sectioning will come later in conjunction with the work in chapter \ref{ch:hci}.

Aim 2 is to measure the perception of high dimension data embeddings across display type.
Chapter \ref{ch:dimensionality}, experimental study of tours across display type, divulges on the experimental design that studies across the display devices: standard 2d monitors, head-tracked 3d displayed on a zSpace, and head-mounted virtual reality goggles. The *spinifex* package will be called from Unity (via C#), which will then render the data projections from the same interface across display types.

Chapter \ref{ch:hci}, human-computer interaction of high dimension data and functions, extends the previous work, creating an immersive virtual space for exploratory data analysis of projections of high dimensional data and function spaces.

Finally, chapter \ref{ch:timeline} lays out the prospective timeline for the remainder of my PhD research.

-->

<!-- Finally, Chapter 6 provides some concluding remarks, discussion, ideas for future research, and so on. Appendixes can contain additional material that don't fit into any chapters, but that you want to put on record. For example, additional tables, output, etc. -->

## 2019_02_14 from zPDFS_FindingManipVars.r

PDFSense_tour repo should be the source of truth for this.

```{r From_zPDFS_FindingManipVars.r}
library(spinifex)
library(ggplot2)
set.seed(1)

## FUNCTION FOR STATIC OUTPPUT, for chap3 use to clean up code chunks.
interpolate2static <- function(.m_tour, .data, .m_var, .cat, .mag =2.4, .angle)
{
  slides <- array2df(array = .m_tour, data = .data, angle = .angle)
  basis_slides <- slides$basis_slides
  data_slides  <- slides$data_slides

  # Initialize
  ## manip var asethetics
  n_slides      <- max(basis_slides$slide)
  p             <- nrow(basis_slides) / n_slides
  col_v         <- rep("grey80", p)
  col_v[.m_var] <- "blue"
  col_v         <- rep(col_v, n_slides)
  siz_v         <- rep(0.3, p)
  siz_v[.m_var] <- 1
  siz_v         <- rep(siz_v, n_slides)
  ## circle
  angle <- seq(0, 2 * pi, length = 180)
  circ  <- data.frame(c_x = cos(angle), c_y = sin(angle))
  circ[nrow(circ)+1, ] <- NA
  ## data asethetics
  data_slides <- data.frame(data_slides, cat = rep(.cat, n_slides))

  grid_b <- grid_t <-
    data.frame(slide = 1:n_slides,
               x = .mag*rep(1:5, 3), y = .mag*rep(3:1, each = 5))
  grid_t$y <- grid_t$y + max(grid_t$y)
  # OUTER JOIN
  basis_grid <- merge(x = basis_slides, y = grid_t, by = "slide", all = TRUE)
  # CROSS JOIN
  circ_grid  <- merge(x = circ, y = grid_t, by = NULL)
  # OUTER JOIN
  data_grid  <- merge(x = data_slides, y = grid_b, by = "slide", all = TRUE)

  # Grpahics
  gg1 <-
    ggplot(data = basis_grid) +
    # AXES LINE SEGMETNS
    geom_segment(aes(x = V1 + x, y = V2 + y, xend = x, yend = y),
                 color = col_v, size = siz_v) +
    # AXES TEXT LABELS
    geom_text(aes(x = V1 + x, y = V2 + y, label = lab_abbr),
              color = col_v, vjust = "outward", hjust = "outward") +
    # AXES FRAME NUM
    geom_text(aes(x = x - .7, y = y + 1.1, label = paste0("frame: ",slide)),
              color = "grey50") +
    # AXES CIRCLE PATH
    geom_path(data = circ_grid, color = "grey80",
              mapping = aes(x = x+c_x, y = y+c_y))

  #===
  gg2 <- gg1 +
    # PROJ DATA POINTS
    geom_point(data = data_grid, size = .2,
               mapping = aes(x = V1 + x, y = V2 + y, color = cat, pch = cat)) +
    # PROJ DATA FRAME NUM
    geom_text(data = data_grid,    color = "grey50",
              mapping = aes(x = x - .7, y = y + 1.1,
                            label = paste0("frame: ",slide))) +
    theme_void() +
    scale_color_brewer(palette = "Dark2") +
    # + coord_fixed()
    theme(legend.position="none",
          panel.border = element_rect(colour = "black", fill = NA))

  # output
  gg2
}


# FIG 7 START ===========================
load("./data/jetsProj_sub.rda")
load("./data/PDFSense_fig7_basis.rda")

PDF7_bas <- fig7_basis
PDF7_dat <- tourr::rescale(jetsProj_sub[, 1:4])
PDF7_cat <- jetsProj_sub$exp
PDF7_m_var_good <- 3
PDF7_m_var_bad <- 4
PDF7_mtour <- manual_tour(basis = PDF7_bas, manip_var = PDF7_m_var)
# play_manual_tour(PDF7_dat, PDF7_bas, 1, angle = .28, axes="bottomleft")

# interpolate2static(.m_tour = PDF7_mtour, .data = PDF7_dat, .m_var = PDF7_m_var_good,
#                    .angle = .28, .cat = PDF7_cat, .mag = 2.4)
# interpolate2static(.m_tour = PDF7_mtour, .data = PDF7_dat, .m_var = PDF7_m_var_bad,
#                    .angle = .28, .cat = PDF7_cat, .mag = 2.4)

# all 4 axes
play_manual_tour(PDF7_dat, PDF7_bas, 1, angle = .28, axes="bottomleft", cat_var = PDF7_cat)
play_manual_tour(PDF7_dat, PDF7_bas, 2, angle = .28, axes="bottomleft", cat_var = PDF7_cat)
play_manual_tour(PDF7_dat, PDF7_bas, 3, angle = .28, axes="bottomleft", cat_var = PDF7_cat)
play_manual_tour(PDF7_dat, PDF7_bas, 4, angle = .28, axes="bottomleft", cat_var = PDF7_cat)

print("!!!!USE 3 for best example, and 4 for worst.!!!!")
##M_VAR, RESULT
# 1, good
# 2, poor
# 3, best
# 4, worst


# FIG 8 START =====================

load("./data/grDIScenter.rda")
load("./data/PDFSense_fig8l_basis.rda")

PDF8_bas <- fig8l_basis
PDF8_dat <- tourr::rescale(grDIScenter[, 1:6])
PDF8_cat <- factor(grDIScenter$disID)
PDF8_m_var <- 6
PDF8_mtour <- manual_tour(basis = PDF8_bas, manip_var = PDF8_m_var)

view_basis(PDF8_bas)
play_manual_tour(PDF8_dat, PDF8_bas, 1, angle = .28, axes="center", cat_var = PDF8_cat)
play_manual_tour(PDF8_dat, PDF8_bas, 2, angle = .28, axes="bottomleft", cat_var = PDF8_cat)
play_manual_tour(PDF8_dat, PDF8_bas, 3, angle = .28, axes="bottomleft", cat_var = PDF8_cat)
play_manual_tour(PDF8_dat, PDF8_bas, 4, angle = .28, axes="bottomleft", cat_var = PDF8_cat)
play_manual_tour(PDF8_dat, PDF8_bas, 5, angle = .28, axes="bottomleft", cat_var = PDF8_cat)
play_manual_tour(PDF8_dat, PDF8_bas, 6, angle = .28, axes="bottomleft", cat_var = PDF8_cat)

print("!!!!USE 6 for best example, and 2 for worst.!!!!")
##M_VAR, RESULT
# 1, green jet.
# 2, poor
# 3, black
# 4, plane
# 5, black and plane
# 6, green and plane
```

# 2019_02_21 from UCS_3dvs2d

<!-- Display types come in a plethora of sizes and technologies each is unique and optimized for specific uses and viewing conditions. It's a rapidly changing and shifting environment with a plethora of applications. Which and how to best use 2D computer minters will generate as many varied opinions as people asked. The question is only exaggerated when 3D display devices are considered. -->

# 2019_03_08 from Lit review. grand tours

<!-- * torus: where a $p$-dimensional torus, $T^p$ is created from a Cartesian product of $p$ unit circles with $T^p \in \mathbb{R}^p$. Unfortunately, uniformity of the parameters does not correlate to uniform points on the surface of the torus. If step distance between frames is fixed, disproportionate time is spent between subspaces. If step distance is change to account for uniform points on the torus then the continuity of the tour is lost.   -->
<!-- * at-random: where each 2-frame is chosen at random without replacement. This affords an assured uniform distribution of subspaces but is far too discontinuous for observation. It also leaves no parameters to control. -->
<!-- * random-walk: combines the continuity of the torus method and the uniformity of the at-random method while leaving room for a control parameter.  -->

# 2019_03_09 from lit review, tours - toy example

<!-- ALREADY USED IN 04-workinprogress, don't use here. -->
<!-- ### Example illustrations -->

<!-- A list of tour notation is given in the appendix section \ref{sec:tour_notation}. -->

<!-- This sections a toy data set of 74 observations of flea beetles across 6 numeric variables corresponding to physical measurements. Each observation belongs to one of 3 species as shown in the color and shape of the data points. Figure \@ref(fig:flea-refframe) shows one frame of a tour (left) and the corresponding reference frame (right) showing the linear combination of the variables onto the projection-space, a visual representation of the basis. -->

<!-- ```{r flea-refframe, results='hide', fig.cap = "(left) one frame of a x-y scatterplot projection, the results of holes tour with a corresponding reference frame indicating the direction and magnitude the variables contribute to the 2D projection."} -->
<!-- f_dat  <- tourr::rescale(flea[,1:6]) -->
<!-- f_cat  <- factor(flea$species) -->
<!-- f_path <- save_history(f_dat, guided_tour(holes())) -->
<!-- f_bas  <- matrix(f_path[,, max(dim(f_path)[3])], ncol=2) -->
<!-- f_mvar <- 5 -->
<!-- f_proj <- data.frame(tourr::rescale(f_dat %*% f_bas)) -->

<!-- view_basis(f_bas, labels = colnames(f_dat)) + -->
<!--   geom_point(data = f_proj,  -->
<!--              mapping = aes(x = X1 - 2, y = X2 - .5, color = f_cat),  -->
<!--              pch = as.integer(f_cat) + 15) -->
<!-- ``` -->

<!-- ```{r flea-basis} -->
<!-- rownames(f_bas) <- colnames(f_dat) -->
<!-- colnames(f_bas) <- c("x", "y") -->
<!-- ``` -->

<!-- Tours view many such frames in sequence, by identifying some target frames and then interpolating between them as shown schematically in figure \@ref(fig:buja05fig), captured from figure 1 of @buja_computational_2005. For illustration figure \@ref(fig:flea-static) lays out frames of a tour, -->
<!-- A html version of a user-controlled steering can be found at https://nspyrison.netlify.com/thesis/flea_manualtour_mvar5/. -->
<!-- The sections below will outline path generation and enumerate display geoms. -->

<!-- (ref:buja05fig-cap) Screen capture of figure 1 from @buja_computational_2005. A schematic representation of randomly generated planes (from a grand tour) and intermediate interpolation planes.  -->

<!-- ```{r buja05fig, echo=F, out.width='70%', fig.cap = "(ref:buja05fig-cap)"} -->
<!-- knitr::include_graphics("./figures/buja05fig.PNG") -->
<!-- ``` -->

<!-- (ref:flea-static-cap) Illustration of a radial manual tour (RO #1), a dynamic version can be viewed at https://nspyrison.netlify.com/thesis/flea_manualtour_mvar5/. -->

<!-- ```{r flea-static, echo=F, warning=F, fig.height=7.2, fig.width=6, out.height='7.2in', out.width='6in', fig.cap = "(ref:flea-static-cap)"} -->
<!-- f_angle <- .27 -->
<!-- f_mtour <- manual_tour(f_bas, manip_var = f_mvar, angle = f_angle) -->
<!-- if(dim(f_mtour)[3] != 15) message( -->
<!--   paste0("!!!!! step3 n_slides != 15 !!!!! n_slides = ", dim(f_mtour)[3])) -->

<!-- #play_manual_tour(f_dat, f_bas, f_mvar, cat_var = f_cat, angle = f_angle) -->
<!-- array2static(.m_tour = f_mtour, .data = f_dat, .m_var = f_mvar, .cat = f_cat) -->
<!-- ``` -->

#2019_03_09 from introduction/ lit review

<!-- TODO: move this to tours lit rev. -->
<!-- This thesis focuses on tour methods for visualizing high-dimensional data. Tours are a family of algorithms for generating paths on the space of low-dimensional ($d=1, 2, 3, ..., p$) projections of high-dimensional ($p$) space. The resulting projection of the data (or model) is displayed using low-dimensional techniques such as histograms, dot plots, scatterplots, or parallel coordinate plots, and the path generates a movie or animation to shows many low-dimensional projections. The method can be applied with other techniques such as machine learning techniques like discriminant analysis, neural networks, support vector machines, to open the black box, and complements dimension reduction techniques like principal component analysis (PCA), multidimensional scaling (MDS) on nonlinear embeddings (e.g. tSNE).  -->