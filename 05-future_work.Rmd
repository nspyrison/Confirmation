---
chapter: 5
knit: "bookdown::render_book"
---

# Future work {#ch:future_work}

## RO #2) Does 2D UCS provide benefits over alternatives?

High dimensional data and models are ubiquitous but viewing them in data space is not trivial. This work quantifies various measurements of 2D UCS implemented in RO #1, and commonly used alternatives. All comparison groups are unsupervised (agnostic of clustering), static, single embeddings in a lower dimension, and would include:

- **Principal Component Analysis (PCA)**, is a linear transformation that orients linear combinations of the variables into basis components and orders them according to the amount of variation. The first principal component is the linear combination that explains the most variation with the second explaining the most of the remaining variation and is orthogonal to all previous components, and so on. 
- **Multi-Dimensional Scaling (MDS)**, non-linear dimension reduction that compares pairwise distances between observations.
- **t-distributed neighbor embeddings (tSNE)**, a nonlinear technique that iterates epochs of 1) constructing a probability distribution for selecting neighboring data and 2), minimizing Kullback-Leibler divergence (a measure of relative entropy).

Unfortunately, static linear projections necessarily cut variation in the components not shown, while non-linear techniques lose transparency back to the original variable space. Tours preserve this transparency to variable-space and keep variation in tack. Providing user-controlled steering of tours should allow for finer structural exploration than the alternatives.

The methodology for this future work is a **case study** comparing benchmark datasets across technique, UCS and leading alternatives. This will be a sufficient comparison if there are enough quantifiable measurements across the different techniques. However, if enough measurements are not comparable across techniques an empirical study analogous to the study suggested in RO # 4 will be considered. Design space includes data sets, techniques, and measures of comparison.

## RO #3) How can UCS be extended to 3D?

The literature has shown positive results for improved accuracy and precision for 3D displays. Dynamic linear projections should have similar gains in 2D projections, and the additional dimension should allow for improved perception of surfaces and dynamic viewing of 3D projections. The research answering RO #1) will be extended to these uses.

The work done in @cordeil_imaxes:_2017 creates a collaborative space for people to engage in immersive data analysis, a generalized platform for data visualization in the Unity game engine. By integrating dynamic linear touring in  3D with the above work offers a consolidated user interface that can be used across various display devices in RO #4.

This is an **algorithm design**, first, the *R* package spinifex will be extended to 3D and function projections will be implemented. After the projections are performed *Unity* will be used to render the embeddings in 3D VR and offer a compatible front end to be used across display devices.

Manipulating 3D spaces may not be straight forward. In section {sec:algorithm} the manipulation space was in 3D, where 2 angles defined a point that was projected back to the 2D projection. If we have to define a 4D manipulation space it may be complex and clunky to navigate. On the other hand, if we can control the projection to 3D with the now 3D reference volume, then navigating 3D space may be very intuitive.

Viewing functions and surfaces have several difficulties in 3D the first of which is occulation, the surfaces in the foreground blocks the view behind it. Opacity, wire mesh, and projection sectioning are ways to address this issue. A second issue is that it may be disorienting or nauseating to watch surfaces folding into each other. 

If UCS happens in real time the angular speed of the tour should be regulated for continuity of observation and to mitigate potentially nauseating movement. 

The design space includes the path generators (outlined in section \ref{sec:path_generation}), geometric display (section \ref{sec:geom_display}), layout in virtual space, dynamic interactions. Tour paths are conceptually straight-forward mapping between values and 3D rendering. Each geometric display will need unique recreation, though 3D scatterplot, parallel coordinate plot and scatterplot matrices (SPLOM) are currently supported in the respective packages in both languages. We will also explore surface and function visualization in 3D. 

## RO #4) Does UCS in 3D displays provide perception benefits over 2D displays? {#UCS_3dvs2d}

The bulk of past touring endeavors have existed whole in 2D, with the exceptions of @nelson_xgobi_1998 and @arms_benefits_1999 who performed an $n=15$ experimental study comparing tasks performed across 2D and 3D touring displays. The XGobi interface was used on a standard 2D monitor while VRGobi (on the C2 setup) was used with head-tracked binocular VR. The 3 accuracy tasks: clustering, intrinsic data dimensionality, and radial sparseness were recorded along with the speed of brushing data. Accuracy was the same for the dimensionality task, while 3D display outperformed 2D on clustering, and even more so on the radial sparsity. However, the time taken to brush a cluster was less than half the time in 2D displays as compared with 3D. 

@wagner_filho_immersive_2018 performed a user study on the perception of linear projections between 2D, 3D, and immersive 3D. The $n=30$ user study created 3D embeddings of multidimensional data via principal component analysis (PCA, described in RO #2, above). Users performed 3 tasks across 2 data sets and 3 displays; 2D, 3D, and immersive 3D. Data sets were chosen to have vastly different amounts of information contained in the 3rd principal component. They find that the introduction of a 3rd dimension in visualization improves task performance (perception error, task error, and completion time) regardless of immersion for only the dataset containing promising information gain in 3D. Independent of the dataset, immersive 3D display led to a larger subjective perception of accuracy and engagement.

The results of @wagner_filho_immersive_2018, @nelson_xgobi_1998 and, @arms_benefits_1999 cast positive light on 3D spaces improving the perception of embeddings of high-dimensional data. Others have found the same for data already in three dimensions. After implementing touring and UCS in 3D spaces (RO #3), the effects of viewing dynamic projections should be quantified across the display type.

I plan to test the efficacy of doing so with the following controlled **usability study**, where every participant will complete every task on every display device. Task order and display device will be randomly assigned to minimize learning bias. Correctness and speed of tasks will be recorded alongside demographic data and subjective 5-point Likert scale survey. A lineup-type model as outlined in @hofmann_graphical_2012 may be employed to quantify the "best" display device.

Tasks will test the perception of structure and surface, varying across the manipulation variable. All tasks will be conducted across at least three display devices: standard 2D monitor, stereoscopic 3D monitor (on a zSpace 200), and head-mounted VR goggles (HTC VIVE). The user interface will be standardized across display devices. The data explored will be of high energy physics experiments already being discussed in publication [@wang_visualizing_2018; @cook_dynamical_2018] and looked at in 2D UCS in appendix \ref{ch:spinifex_paper}.

