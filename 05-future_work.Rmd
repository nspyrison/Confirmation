---
chapter: 5
knit: "bookdown::render_book"
---

# Future work {#ch:future_work}

## RO #2) Does 2D UCS provide benefits over alternatives?

High dimensional data and models are ubiquitous but viewing them in data space is not trivial. This work quantifies various measurements of 2D UCS implemented in RO #1, and commonly used alternatives. All comparison groups are unsupervised (agnostic of clustering), static, single embeddings in a lower dimension, and would include:

- **Principal Component Analysis (PCA)**, is a linear transformation that orients linear combinations of the variables into basis components and orders them according to the amount of variation. The first principal component is the linear combination that explains the most variation with the second explaining the most of the remaining variation and is orthogonal to all previous components, and so on. 
- **Multi-Dimensional Scaling (MDS)**, non-linear dimension reduction that compares pairwise distances between observations.
- **t-distributed neighbor embeddings (tSNE)**, a nonlinear technique that iterates epochs of 1) constructing a probability distribution for selecting neighboring data and 2), minimizing Kullback-Leibler divergence (a measure of relative entropy).

Unfortunately, static linear projections necessarily cut variation in the components not shown, while non-linear techniques lose transparency back to the original variable space. Tours preserve this transparency to variable-space and keep variation in tack. Providing user-controlled steering of tours should allow for finer structural exploration than the alternatives.

The tentative methodology for this future work is a **benchmark comparison study** between UCS and leading alternatives. This will be a sufficient comparison if there are enough quantifiable measurements across the different techniques. However, if enough measurements are not comparable across techniques an empirical study analogous to the study suggested in RO # 4 will be considered. Design space includes data sets, techniques, and measures of comparison.

## RO #3) How can UCS be extended to 3D?

The literature has shown positive results for improved accuracy and precision for 3D displays. Dynamic linear projections should have similar gains in $d=2$ projections, and the additional dimension should allow for improved perception of surfaces and dynamic viewing of $d=3$ projections. The research answering RO #1) will be extended to these uses.

The work done in @cordeil_imaxes:_2017 creates a collaborative space for people to engage in immersive data analysis, a generalized platform for data visualization in the Unity game engine. By integrating dynamic linear touring in  3D with the above work offers a consolidated user interface that can be used across various display devices in RO #4.

This is an **exploratory design**, first the *R* package spinifex will be extended to 3D, and then calling it via the *Unity* package for rendering in 3D VR and offers a compatible front end to be used across display devices.

The design space includes the path generators (outlined in section \ref{sec:path_generation}), geometric display (section \ref{sec:geom_display}), layout in virtual space, dynamic interactions. Tour paths are conceptually straight-forward mapping between values and 3D rendering. Each geometric display will need unique recreation, though 3D scatterplot, parallel coordinate plot and scatterplot matrices (SPLOM) are currently supported in the respective packages in both languages. We will also explore surface and function visualization in 3D. 

## RO #4) Does UCS in 3D displays provide perception benefits over 2D displays? {#UCS_3dvs2d}

The bulk of past touring endeavors have existed whole in 2D, with the exceptions of @nelson_xgobi_1998 and @arms_benefits_1999 who performed a small ($n=15$) experimental study comparing tasks performed across 2D and 3D touring displays. The XGobi interface was used on a standard 2D monitor while VRGobi (on the C2 setup) was used with head-tracked binocular VR. The 3 accuracy tasks: clustering, intrinsic data dimensionality, and radial sparseness were recorded along with the speed of brushing data. Accuracy was the same for the dimensionality task, while 3D display outperformed 2D on clustering, and even more so on the radial sparsity. However, the time taken to brush a cluster was less than half the time in 2D displays as compared with 3D. 

The results of @wagner_filho_immersive_2018, @nelson_xgobi_1998 and, @arms_benefits_1999 cast positive light on 3D spaces improving the perception of embeddings of high-dimensional data, while others have found the same for data already in three dimensions. After implementing touring and UCS in 3D spaces (RO #3), the next step is to quantify the effects across display type.

I plan to test the efficacy of doing so with the following **empirical study**: *randomized full factorial design*, where every participant will complete every task on every display device. Task order and display device will be randomly assigned to minimize learning bias. Correctness and speed of tasks will be recorded alongside demographic data and subjective 5-point Likert scale survey. A lineup-type model as outlined in @hofmann_graphical_2012 may be employed to quantify the "best" display device.

Tasks will test the perception of structure and surface, varying across the manipulation variable. All tasks will be conducted across at least three display devices: standard 2D monitor, stereoscopic 3D monitor (on a zSpace 200), and head-mounted VR goggles (HTC VIVE). The user interface will be standardized across display devices. The data explored will be of high energy physics experiments already being discussed in publication [@wang_visualizing_2018; @cook_dynamical_2018] and looked at in 2D UCS in appendix \ref{ch:spinifex_paper}.

