---
chapter: 5
knit: "bookdown::render_book"
---

# Future work {#ch:future_work}

## RO #2) Does 2D UCS provide benefits over alternatives?

High dimensional data and models are ubiquitous but viewing them in data space is not trivial. This work quanifies various measurements of 2D UCS implemented in RO #1, and commonly used alternatives. All comparison groups are unsupervised (agnostic of clustering) static, single embeddings in lower dimension of the data, and would include:

- **Principal Component Analysis (PCA)**, is a linear transformation that orients linear combinations of the variables into basis components and orders them according to amount of variation. The first principal component is the linear combination that explains the most variation with the second explaining the most of the remaining variation and is orthogonal to the all previous components, and so on. 
- **Multi-Dimensional Scaling (MDS)**, non-linear dimension reduction that compares pairwise distances between observations.
- **t-distributed neighbor embeddings (tSNE)**, a nonlinear technique that iterates epochs of: 1) constructing a probability distributions for selecting neighboring data and 2), minimizing Kullback-Leibler divergence (a measure of relative entropy).

Unfortunately, static linear projections necessarily cut variation in the components not shown, while non-linear techniques lose transparency back to the original variable-space. Tours preserve this transparency to variable-space and keeps variation in tack. Providing user-controlled steering of tour should allow for finer structural exploration than the alternatives.

The tentative methodology for this future work is a **case study** between UCS and leading alternatives. This will be a sufficient comparison if there are enough quantifiable measurements across the different techniques. However, if enough measurements are not comparable across technique an empirical study analogous to the study suggested in RO # 4 will be considered. Design space includes data sets, techniques, and measures of comparison.

## RO #3) How can UCS be extended to 3D?

The literature has shown positive results for improved accuracy and precision for 3D displays. Dynamic linear projections should have similar gains in $d=2$ projections, and the additional dimension should allow for improved perception of 3D surfaces and dynamic viewing of $d=3$ projections.

This work starts with on the work applied in RO #1, and incorporates the recent work of @cordeil_immersive_2019, immersive analytics toolkit (IATK). This integration of technologies will result in a consolidated user interface that can be used across various display device for RO #4.

This **exploratory design** extending UCS to $d=3$ projections is a novel contribution tying together open source work across computer languages and offers a compatible front end to be used across display devices.

## RO #4) Does UCS in 3D displays provide perception benefits over 2D displays? {#UCS_3dvs2d}


The bulk of past touring endeavors have existed whole in 2D, with the exceptions of @nelson_xgobi_1998 and @arms_benefits_1999 whom performed a small ($n=15$) experimental study comparing tasks performed across 2D and 3D touring displays. The XGobi interface was used on a standard 2D monitor while VRGobi (on the C2 setup) was used with head-tracked binocular VR. The 3 accuracy tasks: clustering, intrinsic data dimensionality, and radial sparseness were recorded along with the speed of a brushing data. Accuracy was the same for the dimensionality task, while 3D display outperformed 2D on clustering, and even more so on the radial sparsity. However, time taken to brush a cluster was less than half the time in 2D display as compared with 3D. 

The results of @wagner_filho_immersive_2018, @nelson_xgobi_1998 and, @arms_benefits_1999 cast positive light on 3D spaces improving the perception of embeddings of high-dimensional data. After implementing touring and UCS in 3D spaces (RO #3), I plan to explore the efficacy of doing so with the following empirical study: comparison of 3D touring across display dimension in 4 instances: standard 2D monitor, stereoscopic 3D monitor (on a zSpace 200), and head-mounted VR goggle (HTC VIVE), and immersion in a CAVE environment. Implementation in the game engine Unity will allow for a standardized user interface. Tasks of structure perception will be conducted across 2 data sets of high energy physics data already in publication [@wang_visualizing_2018; @cook_dynamical_2018] and discussed in appendix \ref{ch:spinifex_paper}. Task order will be randomly assigned to minimize learning bias. Participants will perform all tasks on each display devices, for each of the data sets. Time, and accuracy will be tracked, and participants will be asked to fill out a small survey with demographic data and subjective experience on a 5-point Likert scale. The design space of this study includes display type, task type, survey questions, familiarity with 3D, familiarity with linear projections.
